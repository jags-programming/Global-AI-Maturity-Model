# Evaluation Criteria – Data & Infrastructure (GAIMM)

This document defines the evaluation criteria for the **Data & Infrastructure** pillar of the GAIMM framework. Each level includes five granular and progressively sophisticated criteria to assess the maturity of an organization in this dimension.

## Pillar: Data & Infrastructure

Covers data quality, accessibility, availability of tools and compute, APIs, and cloud infrastructure to support AI initiatives.

---

### Level 1: Exploratory

Ad-hoc experimentation; isolated pilots, no AI governance or structure.

1. **Data Accessibility** – Data needed for AI efforts is hard to access, siloed, and not documented.
2. **Data Quality** – No consistent practices to clean, label, or validate data used in models.
3. **Infrastructure Provisioning** – Infrastructure used is basic (e.g., personal laptops or local servers).
4. **Tooling** – AI/ML development relies on individual preferences or open-source tools without standardization.
5. **APIs & Integration** – Little to no availability of internal data services or APIs for AI workflows.

---

### Level 2: Foundational

Initial strategy, emerging roles, basic use cases and compliance practices.

1. **Data Repositories** – Initial central repositories are in place but limited in scale or governance.
2. **Basic Data Governance** – Some efforts to profile and clean data are emerging; data catalogs may exist.
3. **Cloud Readiness** – Some workloads use cloud-based compute, typically on an ad-hoc basis.
4. **Dev Environments** – Basic provisioning of sandbox environments or virtual machines for ML teams.
5. **Internal Data Access** – Initial APIs or data pipelines exist for selected projects.

---

### Level 3: Structured

Centralized governance, defined processes, early scaling, risk and ethics in place.

1. **Data Lake or Warehouse** – Enterprise-level data infrastructure supports integration across functions.
2. **DataOps Practices** – Introduction of version control, lineage tracking, and automated data pipelines.
3. **Scalable Compute** – ML workloads are supported by scalable compute (e.g., cloud GPU clusters).
4. **Standardized Toolkits** – Common tools and environments (e.g., notebooks, model registries) are defined.
5. **API Management** – APIs are documented, reusable, and managed with basic governance.

---

### Level 4: Enterprise-Integrated

AI embedded across functions; measurable impact; aligned with business KPIs.

1. **Enterprise Data Governance** – Well-established policies for data stewardship, access control, and metadata management.
2. **Production-Grade Pipelines** – Reliable and automated ETL/ELT pipelines that support production AI systems.
3. **Resource Orchestration** – Dynamic allocation of compute resources across teams and projects.
4. **ML Infrastructure** – Unified ML platforms support training, testing, deployment, and monitoring.
5. **Data APIs at Scale** – Internal and external APIs enable data-sharing at scale with versioning and SLAs.

---

### Level 5: Transformative

AI drives innovation and competitiveness; adaptive, learning org; continuous value.

1. **Data as a Product** – Teams treat data as a product with owners, service levels, and lifecycle management.
2. **Real-Time Data Infrastructure** – Streaming infrastructure enables real-time AI and decisioning.
3. **Fully Automated MLOps** – End-to-end automation of data preparation, model deployment, and monitoring.
4. **Elastic & Optimized Compute** – Advanced workload optimization and cost-aware scheduling in multi-cloud or hybrid setups.
5. **External Data Integration** – Seamless use of third-party, partner, or open data with governance controls.


